#import data file 
from google.colab import files
uploaded = files.upload()

#Boxplots

# Import libraries
import matplotlib.pyplot as plt
import pandas as pd  # To read data
import numpy as np
import seaborn as sns
 
 
# importing dataset
data = pd.read_csv('/content/FullData.csv') 

fig = plt.figure(figsize =(10, 7))

plt.title("Boxplot showing the growth in GDP and expenditure growth in each sector")
plt.ylabel("Growth in %")

dataarray = data[["GDPGROWTH","HEALTHGROWTH","EDUCATIONGROWTH","MILITARYGROWTH"]].dropna()

sns.boxplot(data = dataarray, showmeans=True)

plt.show()


#Start with PooledOLS and check required assumptions 
!pip install linearmodels
from linearmodels import PooledOLS
import statsmodels.api as sm


exog = sm.tools.tools.add_constant(dataset[['HEALTHGROWTH','EDUCATIONGROWTH','HEALTHGROWTH']])
endog = dataset['GDPGROWTH']
mod = PooledOLS(endog, exog)
pooledOLS_res = mod.fit(cov_type='clustered', cluster_entity=True)

#Store values for checking homoskedasticity graphically
fittedvals_pooled_OLS = pooledOLS_res.predict().fitted_values
residuals_pooled_OLS = pooledOLS_res.resids
print(pooledOLS_res)

#Check condition 3, homoskedasticity and non-aautocorrelation

 # 3A.1 Residuals-Plot for growing Variance Detection
import matplotlib.pyplot as plt
fig, ax = plt.subplots()
ax.scatter(fittedvals_pooled_OLS, residuals_pooled_OLS, color = 'blue')
ax.axhline(0, color = 'r', ls = '--')
ax.set_xlabel('Predicted Values', fontsize = 15)
ax.set_ylabel('Residuals', fontsize = 15)
ax.set_title('Homoskedasticity Test', fontsize = 30)
plt.show()

    # 3A.2 White-Test
from statsmodels.stats.diagnostic import het_white, het_breuschpagan
pooled_OLS_dataset = pd.concat([dataset, residuals_pooled_OLS], axis=1)
pooled_OLS_dataset = pooled_OLS_dataset.drop(['GDPGROWTH'], axis = 1).fillna(0)
exog = sm.tools.tools.add_constant(dataset[['EDUCATIONGROWTH']]).fillna(0)
white_test_results = het_white(pooled_OLS_dataset['residual'], exog)
labels = ['LM-Stat', 'M p-val', 'F-Stat', 'F p-val'] 
print(dict(zip(labels, white_test_results)))

   # 3A.3 Breusch-Pagan-Test
breusch_pagan_test_results = het_breuschpagan(pooled_OLS_dataset['residual'], exog)
labels = ['LM-Stat', 'LM p-val', 'F-Stat', 'F p-val'] 
print(dict(zip(labels, breusch_pagan_test_results)))

# 3A. Homoskedasticity
import matplotlib.pyplot as plt
 # 3A.1 Residuals-Plot for growing Variance Detection
fig, ax = plt.subplots()
ax.scatter(fittedvals_pooled_OLS, residuals_pooled_OLS, color = 'blue')
ax.axhline(0, color = 'r', ls = '--')
ax.set_xlabel('Predicted Values', fontsize = 15)
ax.set_ylabel('Residuals', fontsize = 15)
ax.set_title('Homoskedasticity Test', fontsize = 30)
plt.show()

    # 3.B Non-Autocorrelation, Durbin-Watson-Test
from statsmodels.stats.stattools import durbin_watson

durbin_watson_test_results = durbin_watson(pooled_OLS_dataset['residual']) 
print(durbin_watson_test_results)

#Panel Regression without lagged values 

  #Import Datasets and process data 
import pandas as pd

dataset = pd.read_csv('/content/FullData.csv', usecols = ['COUNTRIES','YEARS','MILITARYGROWTH','EDUCATIONGROWTH','HEALTHGROWTH','GDPGROWTH'])

#data cleaning 
dataset[['HEALTHGROWTH','MILITARYGROWTH','EDUCATIONGROWTH']] = dataset.groupby(['COUNTRIES'])['MILITARYGROWTH','EDUCATIONGROWTH','HEALTHGROWTH'].ffill().bfill()

dataset.set_index(['COUNTRIES','YEARS'], inplace= True)

dataarray = data[["GDPGROWTH","HEALTHGROWTH","EDUCATIONGROWTH","MILITARYGROWTH"]].dropna()
#Perform FE- RE models
from linearmodels import PanelOLS
from linearmodels import RandomEffects

exog = sm.tools.tools.add_constant(dataset[['MILITARYGROWTH','EDUCATIONGROWTH','HEALTHGROWTH']])
endog = dataset['GDPGROWTH']

# random effects model
model_re = RandomEffects(endog, exog) 
re_res = model_re.fit() 

# fixed effects model
model_fe = PanelOLS(endog, exog, entity_effects = True) 
fe_res = model_fe.fit() 

#print results
print(re_res)
print(fe_res)

#Hausman-Test to determine whihc test is the best suited 
import numpy.linalg as la
from scipy import stats
import numpy as np
def hausman(fe, re):
 b = fe.params
 B = re.params
 v_b = fe.cov
 v_B = re.cov
 df = b[np.abs(b) < 1e8].size
 chi2 = np.dot((b - B).T, la.inv(v_b - v_B).dot(b - B)) 
 pval = stats.chi2.sf(chi2, df)
 return chi2, df, pval

hausman_results = hausman(fe_res, re_res) 
print('chi-Squared: ' + str(hausman_results[0]))
print('degrees of freedom: ' + str(hausman_results[1]))
print('p-Value: ' + str(hausman_results[2]))

#Panel Regression simple

  #Import Datasets and process data 
import pandas as pd


dataset = pd.read_csv('/content/FullData.csv', usecols = ['COUNTRIES','YEARS','MILITARYGROWTH','EDUCATIONGROWTH','HEALTHGROWTH','GDPGROWTH'])

#data cleaning 
dataset[['HEALTHGROWTH','MILITARYGROWTH','EDUCATIONGROWTH']] = dataset.groupby(['COUNTRIES'])['MILITARYGROWTH','EDUCATIONGROWTH','HEALTHGROWTH'].ffill().bfill()

dataset.set_index(['COUNTRIES','YEARS'], inplace= True)

#Creating lag columns 
for i in range(5):
  dataset['H' + str(i)] = dataset.groupby(['COUNTRIES'])['HEALTHGROWTH'].shift(i)

for i in range(5):
  dataset['E' + str(i)] = dataset.groupby(['COUNTRIES'])['EDUCATIONGROWTH'].shift(i)

for i in range(5):
  dataset['M' + str(i)] = dataset.groupby(['COUNTRIES'])['MILITARYGROWTH'].shift(i)
  
dataset = dataset.dropna()

print(dataset)


#Start with PooledOLS and check required assumptions 
!pip install linearmodels
from linearmodels import PooledOLS
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
exog =sm.tools.tools.add_constant(dataset[['MILITARYGROWTH','EDUCATIONGROWTH','HEALTHGROWTH']])
endog = dataset['GDPGROWTH']

corr = dataset.corr()
sns.heatmap(corr, 
            xticklabels=corr.columns.values,
            yticklabels=corr.columns.values)

mod = PooledOLS(endog, exog)
pooledOLS_res = mod.fit(cov_type='clustered', cluster_entity=True)

#Store values for checking homoskedasticity graphically
fittedvals_pooled_OLS = pooledOLS_res.predict().fitted_values
residuals_pooled_OLS = pooledOLS_res.resids

print(pooledOLS_res)

#Check condition 3, homoskedasticity and non-aautocorrelation 
    # 3A.2 White-Test
from statsmodels.stats.diagnostic import het_white, het_breuschpagan
pooled_OLS_dataset = pd.concat([dataset, residuals_pooled_OLS], axis=1)
pooled_OLS_dataset = pooled_OLS_dataset.drop(['GDPGROWTH'], axis = 1).fillna(0)
exog = sm.tools.tools.add_constant(dataset['MILITARYGROWTH']).fillna(0)
white_test_results = het_white(pooled_OLS_dataset['residual'], exog)
labels = ['LM-Stat', 'M p-val', 'F-Stat', 'F p-val'] 
print(dict(zip(labels, white_test_results)))

    # 3A.3 Breusch-Pagan-Test
breusch_pagan_test_results = het_breuschpagan(pooled_OLS_dataset['residual'], exog)
labels = ['LM-Stat', 'LM p-val', 'F-Stat', 'F p-val'] 
print(dict(zip(labels, breusch_pagan_test_results)))

  # 3.B Non-Autocorrelation, Durbin-Watson-Test
from statsmodels.stats.stattools import durbin_watson

durbin_watson_test_results = durbin_watson(pooled_OLS_dataset['residual']) 
print(durbin_watson_test_results)


# 3A. Homoskedasticity
import matplotlib.pyplot as plt
 # 3A.1 Residuals-Plot for growing Variance Detection
fig, ax = plt.subplots()
ax.scatter(fittedvals_pooled_OLS, residuals_pooled_OLS, color = 'blue')
ax.axhline(0, color = 'r', ls = '--')
ax.set_xlabel('Predicted Values', fontsize = 15)
ax.set_ylabel('Residuals', fontsize = 15)
ax.set_title('Homoskedasticity Test', fontsize = 30)
plt.show()

#Perform FE- RE models
from linearmodels import PanelOLS
from linearmodels import RandomEffects

exog = dataset['MILITARYGROWTH']
endog = dataset['GDPGROWTH']

# random effects model
model_re = RandomEffects(endog, exog) 
re_res = model_re.fit() 

# fixed effects model
model_fe = PanelOLS(endog, exog, entity_effects = True) 
fe_res = model_fe.fit() 

#print results
print(exog)
print(endog)
print(re_res)
print(fe_res)

#Hausman-Test to determine whihc test is the best suited 
import numpy.linalg as la
from scipy import stats
import numpy as np
def hausman(fe, re):
 b = fe.params
 B = re.params
 v_b = fe.cov
 v_B = re.cov
 df = b[np.abs(b) < 1e8].size
 chi2 = np.dot((b - B).T, la.inv(v_b - v_B).dot(b - B)) 
 pval = stats.chi2.sf(chi2, df)
 return chi2, df, pval

hausman_results = hausman(fe_res, re_res) 
print('chi-Squared: ' + str(hausman_results[0]))
print('degrees of freedom: ' + str(hausman_results[1]))
print('p-Value: ' + str(hausman_results[2]))

